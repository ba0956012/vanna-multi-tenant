import os
import json
import logging
import threading
import multiprocessing
import random
from typing import Dict, Optional
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Form
from fastapi.responses import HTMLResponse, RedirectResponse
from pydantic import BaseModel, Field
from vanna import Agent
from vanna.core.registry import ToolRegistry
from vanna.tools import RunSqlTool
from vanna.tools.agent_memory import (
    SaveQuestionToolArgsTool,
    SearchSavedCorrectToolUsesTool,
    SaveTextMemoryTool,
)
from vanna.servers.fastapi import VannaFastAPIServer
from vanna.integrations.azureopenai import AzureOpenAILlmService
from vanna.integrations.postgres import PostgresRunner
from vanna.integrations.chromadb.agent_memory import ChromaAgentMemory
from vanna.core.user import UserResolver, User, RequestContext
from vanna.core.system_prompt import SystemPromptBuilder
from db import PostgresRunnerPooled
from custom_tools import ListAllMemoriesTool
from templates import (
    get_admin_html,
    get_add_memory_html,
    get_detail_html,
    get_agents_management_html,
    get_create_agent_html,
)
import psycopg2

# Configure Logging
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s.%(msecs)03d [%(process)d:%(thread)d] %(name)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)
logging.getLogger("vanna").setLevel(logging.DEBUG)
logging.getLogger("uvicorn").setLevel(logging.INFO)
logging.getLogger("uvicorn.access").setLevel(logging.INFO)

# Load environment variables
load_dotenv()

# Configuration - Azure OpenAI only
azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
azure_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

# Database connection pool configuration
USE_CONNECTION_POOL = os.getenv("USE_CONNECTION_POOL", "true").lower() == "true"
DB_POOL_MIN_CONN = int(os.getenv("DB_POOL_MIN_CONN", "2"))
DB_POOL_MAX_CONN = int(os.getenv("DB_POOL_MAX_CONN", "10"))

AGENTS_CONFIG_FILE = "./agents_config.json"
AGENT_DATA_DIR = "./agent_data"
BASE_AGENT_PORT = 8101  # Agent ports å¾ 8001 é–‹å§‹
VANNA_HOST = os.getenv("VANNA_HOST", "")

# === å…¨åŸŸå„²å­˜ ===
agent_configs: Dict[str, dict] = {}
agent_processes: Dict[str, multiprocessing.Process] = {}
agent_ports: Dict[str, int] = {}
lock = threading.Lock()


def ensure_agent_data_dir():
    if not os.path.exists(AGENT_DATA_DIR):
        os.makedirs(AGENT_DATA_DIR)


def save_agents_config():
    with open(AGENTS_CONFIG_FILE, "w", encoding="utf-8") as f:
        # å„²å­˜è¨­å®šå’Œ port å°æ‡‰
        save_data = {}
        for agent_id, config in agent_configs.items():
            save_data[agent_id] = {**config, "port": agent_ports.get(agent_id)}
        json.dump(save_data, f, indent=2, ensure_ascii=False)
    logger.info(f"Saved {len(agent_configs)} agent configs")


def load_agents_config() -> Dict[str, dict]:
    if os.path.exists(AGENTS_CONFIG_FILE):
        with open(AGENTS_CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def get_next_available_port() -> int:
    """å–å¾—ä¸‹ä¸€å€‹å¯ç”¨çš„ port"""
    used_ports = set(agent_ports.values())
    port = BASE_AGENT_PORT
    while port in used_ports:
        port += 1
    return port


# === å‹•æ…‹ System Prompt Builder ===
class DynamicSystemPromptBuilder(SystemPromptBuilder):
    def __init__(self, system_prompt: str):
        self.system_prompt = system_prompt

    async def build_system_prompt(
        self, user: User, tool_schemas: list, context: dict = None
    ) -> str:
        prompt = self.system_prompt
        if tool_schemas:
            prompt += "\n\n## å¯ç”¨å·¥å…·\n"
            for tool in tool_schemas:
                if isinstance(tool, dict):
                    name = tool.get("name") or tool.get("function", {}).get("name", "unknown")
                    description = tool.get("description") or tool.get("function", {}).get("description", "")
                    prompt += f"\n### {name}\n{description}\n"
        return prompt


# === Agent Server é€²ç¨‹å‡½æ•¸ ===
def run_agent_server(agent_id: str, config: dict, port: int):
    """åœ¨ç¨ç«‹é€²ç¨‹ä¸­é‹è¡Œ agent server"""
    ensure_agent_data_dir()

    # å»ºç«‹ LLM
    llm = AzureOpenAILlmService(
        model=azure_deployment_name,
        api_key=azure_api_key,
        azure_endpoint=azure_endpoint,
        api_version=azure_api_version,
    )

    # å»ºç«‹ Memory
    persist_dir = f"{AGENT_DATA_DIR}/chroma_db_{agent_id}"
    memory = ChromaAgentMemory(
        persist_directory=persist_dir, collection_name=f"vanna_{agent_id}"
    )

    # å»ºç«‹ DB é€£ç·šï¼ˆå¯é¸æ“‡ä½¿ç”¨é€£ç·šæ± æˆ–æ¯æ¬¡æ–°å»ºé€£ç·šï¼‰
    pg_user = config.get("postgres_user")
    pg_password = config.get("postgres_password")
    pg_host = config.get("postgres_host")
    pg_port = config.get("postgres_port") or "5432"
    pg_db = config.get("postgres_db")
    connection_string = f"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}"

    # æ ¹æ“šé…ç½®é¸æ“‡é€£ç·šæ–¹å¼
    if USE_CONNECTION_POOL:
        logger.info(f"Agent '{agent_id}' using connection pool (min={DB_POOL_MIN_CONN}, max={DB_POOL_MAX_CONN})")
        db_tool = RunSqlTool(
            sql_runner=PostgresRunnerPooled(
                connection_string=connection_string,
                minconn=DB_POOL_MIN_CONN,
                maxconn=DB_POOL_MAX_CONN,
            )
        )
    else:
        logger.info(f"Agent '{agent_id}' using new connection per request")
        db_tool = RunSqlTool(
            sql_runner=PostgresRunner(connection_string=connection_string)
        )

    # å»ºç«‹ Tools
    tools = ToolRegistry()
    tools.register_local_tool(db_tool, access_groups=["admin", "user"])
    # tools.register_local_tool(SaveQuestionToolArgsTool(), access_groups=["admin"])
    # tools.register_local_tool(SearchSavedCorrectToolUsesTool(), access_groups=["admin", "user"])
    # tools.register_local_tool(SaveTextMemoryTool(), access_groups=["admin", "user"])
    # tools.register_local_tool(VisualizeDataTool(), access_groups=["admin", "user"])
    tools.register_local_tool(ListAllMemoriesTool(), access_groups=["admin", "user"])

    # User Resolver
    class SimpleUserResolver(UserResolver):
        async def resolve_user(self, request_context: RequestContext) -> User:
            user_email = request_context.get_cookie("vanna_email") or "guest@example.com"
            group = "admin" if user_email in ["admin@example.com"] else "user"
            return User(id=user_email, email=user_email, group_memberships=[group])

    # å»ºç«‹ Agent
    system_prompt = config.get("system_prompt", "ä½ æ˜¯ä¸€å€‹æ•¸æ“šåˆ†æåŠ©æ‰‹")

    agent = Agent(
        llm_service=llm,
        tool_registry=tools,
        user_resolver=SimpleUserResolver(),
        agent_memory=memory,
        system_prompt_builder=DynamicSystemPromptBuilder(system_prompt),
    )

    # å•Ÿå‹• Server
    # FastAPI çš„ async è·¯ç”±å¤©ç”Ÿæ”¯æ´ä¸¦ç™¼ï¼Œuvicorn é è¨­ä½¿ç”¨ asyncio event loop
    # å¯ä»¥åŒæ™‚è™•ç†å¤šå€‹è«‹æ±‚ï¼Œç„¡éœ€é¡å¤–è¨­å®š workers
    logger.info(f"Starting agent '{agent_id}' on port {port}")
    server = VannaFastAPIServer(agent)
    server.run(host="0.0.0.0", port=port)


def start_agent(agent_id: str, config: dict, port: int = None):
    """å•Ÿå‹•ä¸€å€‹ agent server é€²ç¨‹"""
    if port is None:
        port = get_next_available_port()

    process = multiprocessing.Process(
        target=run_agent_server, args=(agent_id, config, port), daemon=True
    )
    process.start()

    agent_processes[agent_id] = process
    agent_ports[agent_id] = port
    logger.info(f"Agent '{agent_id}' started on port {port}, PID: {process.pid}")
    return port


def stop_agent(agent_id: str):
    """åœæ­¢ä¸€å€‹ agent server é€²ç¨‹"""
    if agent_id in agent_processes:
        process = agent_processes[agent_id]
        process.terminate()
        process.join(timeout=5)
        del agent_processes[agent_id]
        if agent_id in agent_ports:
            del agent_ports[agent_id]
        logger.info(f"Agent '{agent_id}' stopped")


# === FastAPI ç®¡ç† App ===
app = FastAPI(
    title="Vanna Multi-Agent Server",
    description="""
    ## å¤š Agent ç®¡ç†ç³»çµ±
    
    é€™å€‹ API æä¾›å®Œæ•´çš„ Agent ç”Ÿå‘½é€±æœŸç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬:
    - å»ºç«‹,åˆªé™¤,é‡å•Ÿ Agent
    - ç®¡ç† Agent çš„ ChromaDB è¨˜æ†¶
    - è‡ªå‹•ç”Ÿæˆ Few-shot è¨“ç·´è³‡æ–™
    
    ### é é¢
    - **ç®¡ç†ä»‹é¢**: `/admin/agents` - Agent åˆ—è¡¨ç®¡ç†
    - **è¨˜æ†¶ç®¡ç†**: `/admin/memory` - ChromaDB è¨˜æ†¶ç®¡ç†
    - **API æ–‡æª”**: `/docs` - Swagger UI (æœ¬é é¢)
    - **ReDoc**: `/redoc` - æ›¿ä»£æ–‡æª”ä»‹é¢
    
    ### API ç«¯é»
    æ‰€æœ‰ API ç«¯é»éƒ½åœ¨ `/api` è·¯å¾‘ä¸‹
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)


# === å–å¾— Agent çš„ ChromaDB Memory ===
def get_agent_memory(agent_id: str, create_if_not_exists: bool = False) -> ChromaAgentMemory:
    """å–å¾—æŒ‡å®š agent çš„ ChromaDB memory
    
    Args:
        agent_id: Agent ID
        create_if_not_exists: å¦‚æœç›®éŒ„ä¸å­˜åœ¨æ˜¯å¦è‡ªå‹•å»ºç«‹(é è¨­ False)
    """
    persist_dir = f"{AGENT_DATA_DIR}/chroma_db_{agent_id}"
    
    if not os.path.exists(persist_dir):
        if create_if_not_exists:
            os.makedirs(persist_dir, exist_ok=True)
            logger.info(f"Created memory directory for agent '{agent_id}'")
        else:
            raise HTTPException(404, f"Agent '{agent_id}' memory not found")
    
    return ChromaAgentMemory(
        persist_directory=persist_dir, collection_name=f"vanna_{agent_id}"
    )


class AgentConfig(BaseModel):
    """Agent configuration model"""
    agent_id: str = Field(..., description="Agent unique ID", json_schema_extra={"example": "pos_sales_agent"})
    description: str = Field("", description="Agent description", json_schema_extra={"example": "POS Sales Analysis System"})
    postgres_user: str = Field(..., description="PostgreSQL username", json_schema_extra={"example": "postgres"})
    postgres_password: str = Field(..., description="PostgreSQL password")
    postgres_host: str = Field(..., description="PostgreSQL host", json_schema_extra={"example": "localhost"})
    postgres_port: str = Field("5432", description="PostgreSQL port", json_schema_extra={"example": "5432"})
    postgres_db: str = Field(..., description="PostgreSQL database name", json_schema_extra={"example": "pos_sales"})
    system_prompt: Optional[str] = Field("", description="Agent system prompt (ç•™ç©ºå‰‡è‡ªå‹•å¾è³‡æ–™åº«ç”Ÿæˆ)")
    
    class Config:
        json_schema_extra = {
            "example": {
                "agent_id": "pos_sales_agent",
                "description": "POS Sales Analysis System",
                "postgres_user": "postgres",
                "postgres_password": "your_password",
                "postgres_host": "localhost",
                "postgres_port": "5432",
                "postgres_db": "pos_sales",
                "system_prompt": ""
            }
        }


class AddMemoryRequest(BaseModel):
    """æ–°å¢è¨˜æ†¶è«‹æ±‚æ¨¡å‹"""
    question: str = Field(..., description="å•é¡Œæè¿°", example="æŸ¥è©¢ä»Šå¤©çš„éŠ·å”®ç¸½é¡")
    tool_name: str = Field(..., description="å·¥å…·åç¨±", example="run_sql")
    args: dict = Field(
        default_factory=dict,
        description="å·¥å…·åƒæ•¸",
        example={"sql": "SELECT SUM(total_amount) FROM pos_sale WHERE DATE(sale_date) = CURRENT_DATE"}
    )
    metadata: dict = Field(
        default_factory=dict,
        description="é¡å¤–çš„ metadata",
        example={"category": "sales", "auto_generated": False}
    )
    
    class Config:
        schema_extra = {
            "example": {
                "question": "æŸ¥è©¢ä»Šå¤©çš„éŠ·å”®ç¸½é¡",
                "tool_name": "run_sql",
                "args": {
                    "sql": "SELECT SUM(total_amount) FROM pos_sale WHERE DATE(sale_date) = CURRENT_DATE"
                },
                "metadata": {
                    "category": "sales",
                    "auto_generated": False
                }
            }
        }

@app.post("/api/agents", tags=["Agent Management"], summary="å»ºç«‹æ–° Agent")
async def register_agent(config: AgentConfig):
    """
    å‹•æ…‹æ–°å¢ agent(ä¸éœ€é‡å•Ÿæœå‹™)
    
    å»ºç«‹ä¸€å€‹æ–°çš„ Agent å¯¦ä¾‹ï¼Œæœƒè‡ªå‹•:
    1. é©—è­‰è³‡æ–™åº«é€£ç·šåƒæ•¸
    2. å¦‚æœæœªæä¾› system_promptï¼Œè‡ªå‹•å¾è³‡æ–™åº«ç”Ÿæˆ
    3. åˆ†é…å¯ç”¨çš„ port
    4. å•Ÿå‹•ç¨ç«‹çš„ Agent é€²ç¨‹
    5. å„²å­˜è¨­å®šåˆ° agents_config.json
    
    Returns:
        - message: å»ºç«‹çµæœè¨Šæ¯
        - port: åˆ†é…çš„ port è™Ÿ
        - url: Agent çš„è¨ªå• URL
        - agents: æ‰€æœ‰ Agent åˆ—è¡¨
        - system_prompt_generated: æ˜¯å¦è‡ªå‹•ç”Ÿæˆäº† system_prompt
    """
    with lock:
        if config.agent_id in agent_configs:
            raise HTTPException(400, f"Agent '{config.agent_id}' already exists")

        config_dict = config.dict()

        # é©—è­‰å¿…è¦åƒæ•¸
        if not all([config.postgres_user, config.postgres_password, config.postgres_host, config.postgres_db]):
            raise HTTPException(400, "Missing required postgres connection parameters")

        # å¦‚æœæ²’æœ‰æä¾› system_promptï¼Œè‡ªå‹•å¾è³‡æ–™åº«ç”Ÿæˆ
        system_prompt_generated = False
        if not config_dict.get("system_prompt") or config_dict["system_prompt"].strip() == "":
            logger.info(f"Generating system prompt from database for agent '{config.agent_id}'")
            try:
                conn = psycopg2.connect(
                    host=config.postgres_host,
                    port=config.postgres_port,
                    user=config.postgres_user,
                    password=config.postgres_password,
                    dbname=config.postgres_db,
                    connect_timeout=10
                )
                
                config_dict["system_prompt"] = generate_system_prompt_from_db(conn, config.postgres_db)
                system_prompt_generated = True
                conn.close()
                logger.info(f"Successfully generated system prompt for agent '{config.agent_id}'")
            except Exception as e:
                logger.error(f"Failed to generate system prompt: {e}")
                raise HTTPException(500, f"ç„¡æ³•é€£æ¥è³‡æ–™åº«æˆ–ç”Ÿæˆ system prompt: {e}")

        # å•Ÿå‹• agent server
        port = start_agent(config.agent_id, config_dict)

        # å„²å­˜è¨­å®š
        agent_configs[config.agent_id] = config_dict
        save_agents_config()

    return {
        "message": f"Agent '{config.agent_id}' created",
        "port": port,
        "url": f"http://{VANNA_HOST}:{port}",
        "agents": list(agent_configs.keys()),
        "system_prompt_generated": system_prompt_generated,
    }


@app.get("/api/agents", tags=["Agent Management"], summary="åˆ—å‡ºæ‰€æœ‰ Agents")
async def list_agents():
    """
    åˆ—å‡ºæ‰€æœ‰å·²è¨»å†Šçš„ agents
    
    Returns:
        - agents: Agent åˆ—è¡¨ï¼ŒåŒ…å« ID,port,URL,é‹è¡Œç‹€æ…‹
    """
    agents_info = []
    for agent_id in agent_configs.keys():
        port = agent_ports.get(agent_id)
        process = agent_processes.get(agent_id)
        agents_info.append({
            "agent_id": agent_id,
            "port": port,
            "url": f"http://{VANNA_HOST}:{port}/api/vanna/v2/chat_sse" if port else None,
            "running": process.is_alive() if process else False,
        })
    return {"agents": agents_info}


@app.delete("/api/agents/{agent_id}", tags=["Agent Management"], summary="åˆªé™¤ Agent")
async def remove_agent(agent_id: str, delete_memory: bool = False):
    """
    ç§»é™¤æŒ‡å®šçš„ agent
    
    Args:
        agent_id: Agent ID
        delete_memory: æ˜¯å¦åŒæ™‚åˆªé™¤ ChromaDB è¨˜æ†¶ (é è¨­ False)
        
    Returns:
        - message: åˆªé™¤çµæœè¨Šæ¯
        - memory_deleted: æ˜¯å¦å·²åˆªé™¤è¨˜æ†¶
    """
    with lock:
        if agent_id not in agent_configs:
            raise HTTPException(404, f"Agent '{agent_id}' not found")

        stop_agent(agent_id)
        del agent_configs[agent_id]
        save_agents_config()
        
        # åˆªé™¤ ChromaDB è¨˜æ†¶
        memory_deleted = False
        if delete_memory:
            import shutil
            memory_dir = f"{AGENT_DATA_DIR}/chroma_db_{agent_id}"
            if os.path.exists(memory_dir):
                try:
                    shutil.rmtree(memory_dir)
                    memory_deleted = True
                    logger.info(f"Deleted memory for agent '{agent_id}'")
                except Exception as e:
                    logger.error(f"Failed to delete memory: {e}")

    return {
        "message": f"Agent '{agent_id}' removed",
        "memory_deleted": memory_deleted
    }


@app.post("/api/agents/{agent_id}/restart", tags=["Agent Management"], summary="é‡å•Ÿ Agent")
async def restart_agent_api(agent_id: str):
    """
    é‡å•ŸæŒ‡å®šçš„ agent
    
    æœƒåœæ­¢ç¾æœ‰é€²ç¨‹ä¸¦ä½¿ç”¨ç›¸åŒçš„ port é‡æ–°å•Ÿå‹•
    
    Args:
        agent_id: Agent ID
        
    Returns:
        - message: é‡å•Ÿçµæœè¨Šæ¯
        - port: Agent çš„ port è™Ÿ
    """
    with lock:
        if agent_id not in agent_configs:
            raise HTTPException(404, f"Agent '{agent_id}' not found")

        config = agent_configs[agent_id]
        old_port = agent_ports.get(agent_id)

        stop_agent(agent_id)
        port = start_agent(agent_id, config, old_port)

    return {"message": f"Agent '{agent_id}' restarted", "port": port}


@app.get("/", include_in_schema=False)
async def root():
    return RedirectResponse("/admin/agents")


@app.get("/admin/agents", response_class=HTMLResponse, include_in_schema=False)
async def agents_management_page(message: str = None):
    """Agent ç®¡ç†é é¢"""
    agents_info = []
    for agent_id in agent_configs.keys():
        port = agent_ports.get(agent_id)
        process = agent_processes.get(agent_id)
        config = agent_configs.get(agent_id, {})
        agents_info.append({
            "agent_id": agent_id,
            "description": config.get("description", ""),
            "port": port,
            "url": f"http://localhost:{port}" if port else "#",
            "running": process.is_alive() if process else False,
        })
    return get_agents_management_html(agents_info, message)


@app.get("/admin/agents/new", response_class=HTMLResponse, include_in_schema=False)
async def create_agent_page(message: str = None):
    """æ–°å¢ Agent é é¢"""
    return get_create_agent_html(message)


@app.post("/admin/agents/new", response_class=HTMLResponse, include_in_schema=False)
async def create_agent_submit(
    agent_id: str = Form(...),
    description: str = Form(""),
    postgres_user: str = Form(...),
    postgres_password: str = Form(...),
    postgres_host: str = Form(...),
    postgres_port: str = Form("5432"),
    postgres_db: str = Form(...),
    system_prompt: str = Form(""),
):
    """è™•ç†æ–°å¢ Agent è¡¨å–®"""
    with lock:
        if agent_id in agent_configs:
            return get_create_agent_html(f"âŒ Agent '{agent_id}' å·²å­˜åœ¨")

        config_dict = {
            "agent_id": agent_id,
            "description": description,
            "postgres_user": postgres_user,
            "postgres_password": postgres_password,
            "postgres_host": postgres_host,
            "postgres_port": postgres_port,
            "postgres_db": postgres_db,
            "system_prompt": system_prompt,
        }

        # é©—è­‰å¿…è¦åƒæ•¸
        if not all([postgres_user, postgres_password, postgres_host, postgres_db]):
            return get_create_agent_html("âŒ ç¼ºå°‘å¿…è¦çš„è³‡æ–™åº«é€£ç·šåƒæ•¸")

        try:
            # å¦‚æœæ²’æœ‰æä¾› system_promptï¼Œè‡ªå‹•å¾è³‡æ–™åº«ç”Ÿæˆ
            if not system_prompt or system_prompt.strip() == "":
                logger.info(f"Generating system prompt from database for agent '{agent_id}'")
                try:
                    conn = psycopg2.connect(
                        host=postgres_host,
                        port=postgres_port,
                        user=postgres_user,
                        password=postgres_password,
                        dbname=postgres_db,
                        connect_timeout=10
                    )
                    
                    config_dict["system_prompt"] = generate_system_prompt_from_db(conn, postgres_db)
                    conn.close()
                    logger.info(f"Successfully generated system prompt for agent '{agent_id}'")
                except Exception as e:
                    logger.error(f"Failed to generate system prompt: {e}")
                    return get_create_agent_html(f"âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«æˆ–ç”Ÿæˆ system prompt: {e}")
            
            # å•Ÿå‹• agent server
            port = start_agent(agent_id, config_dict)

            # å„²å­˜è¨­å®š
            agent_configs[agent_id] = config_dict
            save_agents_config()

            return RedirectResponse(f"/admin/agents?message=Agent '{agent_id}' created successfully (Port: {port})", status_code=302)
        except Exception as e:
            logger.error(f"Failed to create agent: {e}")
            return get_create_agent_html(f"âŒ å»ºç«‹å¤±æ•—: {e}")


@app.get("/api")
async def api_root():
    return {
        "message": "Vanna Multi-Agent Server",
        "endpoints": {
            "list_agents": "GET /admin/agents",
            "create_agent": "POST /admin/agents",
            "remove_agent": "DELETE /admin/agents/{agent_id}",
            "restart_agent": "POST /admin/agents/{agent_id}/restart",
            "memory_ui": "GET /admin/memory",
        },
        "agents": [
            {"id": aid, "port": agent_ports.get(aid), "url": f"http://{VANNA_HOST}:{agent_ports.get(aid)}/api/vanna/v2/chat_sse"}
            for aid in agent_configs.keys()
        ],
    }


# === è¨˜æ†¶ç®¡ç†é é¢ ===
@app.get("/admin/memory", response_class=HTMLResponse, include_in_schema=False)
async def memory_admin_page(agent_id: str = None, message: str = None):
    """è¨˜æ†¶ç®¡ç†ä¸»é é¢"""
    agents_info = []
    for aid in agent_configs.keys():
        port = agent_ports.get(aid)
        process = agent_processes.get(aid)
        agents_info.append({
            "agent_id": aid,
            "port": port,
            "running": process.is_alive() if process else False,
        })
    
    memories = None
    if agent_id and agent_id in agent_configs:
        try:
            memory = get_agent_memory(agent_id)
            collection = memory._get_collection()
            result = collection.get()
            
            memories = []
            if result["ids"]:
                for i, mid in enumerate(result["ids"]):
                    md = result["metadatas"][i]
                    memories.append({
                        "id": mid,
                        "question": md.get("question", ""),
                        "tool_name": md.get("tool_name", ""),
                        "timestamp": md.get("timestamp", ""),
                    })
                # æŒ‰æ™‚é–“æ’åº
                memories.sort(key=lambda x: x["timestamp"] or "", reverse=True)
        except Exception as e:
            logger.error(f"Error loading memories: {e}")
            memories = []
    
    return get_admin_html(agents_info, agent_id, memories, message)


@app.get("/admin/memory/{agent_id}/add", response_class=HTMLResponse, include_in_schema=False)
async def add_memory_page(agent_id: str):
    """æ–°å¢è¨˜æ†¶é é¢"""
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    return get_add_memory_html(agent_id)


@app.post("/admin/memory/{agent_id}/add", include_in_schema=False)
async def add_memory_submit(
    agent_id: str,
    question: str = Form(...),
    tool_name: str = Form(...),
    args_json: str = Form("{}"),
    metadata_json: str = Form("{}"),
):
    """æ–°å¢è¨˜æ†¶"""
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    try:
        args = json.loads(args_json or "{}")
        metadata = json.loads(metadata_json or "{}")
    except json.JSONDecodeError:
        raise HTTPException(400, "JSON æ ¼å¼éŒ¯èª¤")
    
    memory = get_agent_memory(agent_id)
    context = RequestContext(user=User(id="admin"))
    
    await memory.save_tool_usage(
        question=question,
        tool_name=tool_name,
        args=args,
        context=context,
        success=True,
        metadata=metadata,
    )
    
    return RedirectResponse(f"/admin/memory?agent_id={agent_id}&message=è¨˜æ†¶å·²æ–°å¢", status_code=302)


@app.get("/admin/memory/{agent_id}/detail/{memory_id}", response_class=HTMLResponse, include_in_schema=False)
async def memory_detail_page(agent_id: str, memory_id: str):
    """è¨˜æ†¶è©³æƒ…é é¢"""
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    memory = get_agent_memory(agent_id)
    collection = memory._get_collection()
    result = collection.get(ids=[memory_id])
    
    if not result["ids"]:
        raise HTTPException(404, "Memory not found")
    
    md = result["metadatas"][0]
    doc = result["documents"][0] if result["documents"] else ""
    
    memory_data = {
        "id": memory_id,
        "question": md.get("question", ""),
        "tool_name": md.get("tool_name", ""),
        "timestamp": md.get("timestamp", ""),
        "args_json": md.get("args_json", "{}"),
        "document": doc,
    }
    
    return get_detail_html(agent_id, memory_data)


@app.get("/admin/memory/{agent_id}/delete/{memory_id}", include_in_schema=False)
async def delete_memory(agent_id: str, memory_id: str):
    """åˆªé™¤è¨˜æ†¶"""
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    memory = get_agent_memory(agent_id)
    context = RequestContext(user=User(id="admin"))
    
    await memory.delete_by_id(context=context, memory_id=memory_id)
    
    return RedirectResponse(f"/admin/memory?agent_id={agent_id}&message=è¨˜æ†¶å·²åˆªé™¤", status_code=302)


# === Memory Management API ===
@app.get("/api/agents/{agent_id}/memories", tags=["Memory Management"], summary="åˆ—å‡º Agent çš„æ‰€æœ‰è¨˜æ†¶")
async def list_memories(agent_id: str, limit: int = 100):
    """
    åˆ—å‡ºæŒ‡å®š agent çš„æ‰€æœ‰è¨˜æ†¶
    
    Args:
        agent_id: Agent ID
        limit: è¿”å›è¨˜æ†¶æ•¸é‡é™åˆ¶ (é è¨­ 100)
        
    Returns:
        - memories: è¨˜æ†¶åˆ—è¡¨
        - total: ç¸½è¨˜æ†¶æ•¸é‡
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    try:
        memory = get_agent_memory(agent_id)
        collection = memory._get_collection()
        result = collection.get()
        
        memories = []
        if result["ids"]:
            for i, mid in enumerate(result["ids"]):
                md = result["metadatas"][i]
                memories.append({
                    "id": mid,
                    "question": md.get("question", ""),
                    "tool_name": md.get("tool_name", ""),
                    "timestamp": md.get("timestamp", ""),
                    "args_json": md.get("args_json", "{}"),
                })
            # æŒ‰æ™‚é–“æ’åº
            memories.sort(key=lambda x: x["timestamp"] or "", reverse=True)
            memories = memories[:limit]
        
        return {
            "agent_id": agent_id,
            "memories": memories,
            "total": len(result["ids"]) if result["ids"] else 0
        }
    except Exception as e:
        logger.error(f"Failed to list memories: {e}")
        raise HTTPException(500, f"Failed to list memories: {e}")


@app.post("/api/agents/{agent_id}/memories", tags=["Memory Management"], summary="æ–°å¢è¨˜æ†¶")
async def add_memory_api(agent_id: str, request: AddMemoryRequest):
    """
    ç‚ºæŒ‡å®š agent æ–°å¢è¨˜æ†¶
    
    Args:
        agent_id: Agent ID
        request: è¨˜æ†¶è³‡æ–™
        
    Returns:
        - message: æ–°å¢çµæœè¨Šæ¯
        
    Example:
        ```json
        {
            "question": "æŸ¥è©¢ä»Šå¤©çš„éŠ·å”®ç¸½é¡",
            "tool_name": "run_sql",
            "args": {
                "sql": "SELECT SUM(total_amount) FROM pos_sale WHERE DATE(sale_date) = CURRENT_DATE"
            }
        }
        ```
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    try:
        memory = get_agent_memory(agent_id, create_if_not_exists=True)
        context = RequestContext(user=User(id="admin"))
        
        await memory.save_tool_usage(
            question=request.question,
            tool_name=request.tool_name,
            args=request.args,
            context=context,
            success=True,
            metadata=request.metadata,
        )
        
        return {"message": f"Memory added to agent '{agent_id}'"}
    except Exception as e:
        logger.error(f"Failed to add memory: {e}")
        raise HTTPException(500, f"Failed to add memory: {e}")


@app.get("/api/agents/{agent_id}/memories/{memory_id}", tags=["Memory Management"], summary="å–å¾—è¨˜æ†¶è©³æƒ…")
async def get_memory_detail(agent_id: str, memory_id: str):
    """
    å–å¾—æŒ‡å®šè¨˜æ†¶çš„è©³ç´°è³‡è¨Š
    
    Args:
        agent_id: Agent ID
        memory_id: Memory ID
        
    Returns:
        è¨˜æ†¶çš„å®Œæ•´è³‡è¨Š
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    try:
        memory = get_agent_memory(agent_id)
        collection = memory._get_collection()
        result = collection.get(ids=[memory_id])
        
        if not result["ids"]:
            raise HTTPException(404, "Memory not found")
        
        md = result["metadatas"][0]
        doc = result["documents"][0] if result["documents"] else ""
        
        return {
            "id": memory_id,
            "question": md.get("question", ""),
            "tool_name": md.get("tool_name", ""),
            "timestamp": md.get("timestamp", ""),
            "args_json": md.get("args_json", "{}"),
            "document": doc,
            "metadata": md
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get memory detail: {e}")
        raise HTTPException(500, f"Failed to get memory detail: {e}")


@app.delete("/api/agents/{agent_id}/memories/{memory_id}", tags=["Memory Management"], summary="åˆªé™¤è¨˜æ†¶")
async def delete_memory_api(agent_id: str, memory_id: str):
    """
    åˆªé™¤æŒ‡å®šçš„è¨˜æ†¶
    
    Args:
        agent_id: Agent ID
        memory_id: Memory ID
        
    Returns:
        - message: åˆªé™¤çµæœè¨Šæ¯
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    try:
        memory = get_agent_memory(agent_id)
        context = RequestContext(user=User(id="admin"))
        
        await memory.delete_by_id(context=context, memory_id=memory_id)
        
        return {"message": f"Memory '{memory_id}' deleted from agent '{agent_id}'"}
    except Exception as e:
        logger.error(f"Failed to delete memory: {e}")
        raise HTTPException(500, f"Failed to delete memory: {e}")


# === Auto Generate System Prompt ===
def generate_system_prompt_from_db(conn, db_name: str) -> str:
    """å¾ PostgreSQL è³‡æ–™åº«è‡ªå‹•ç”Ÿæˆ system prompt
    
    Args:
        conn: PostgreSQL é€£æ¥
        db_name: è³‡æ–™åº«åç¨±
        
    Returns:
        å®Œæ•´çš„ system prompt å­—ä¸²
    """
    cur = conn.cursor()
    
    # å–å¾—æ‰€æœ‰è¡¨
    cur.execute("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
        ORDER BY table_name;
    """)
    tables = [r[0] for r in cur.fetchall()]
    
    # å»ºç«‹ system prompt
    prompt_parts = []
    prompt_parts.append(f"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ•¸æ“šåˆ†æåŠ©æ‰‹ï¼Œå°ˆé–€å”åŠ©åˆ†æ {db_name} è³‡æ–™åº«ã€‚")
    prompt_parts.append(f"\n## è³‡æ–™åº«çµæ§‹ (PostgreSQL: {db_name})\n")
    prompt_parts.append("### è³‡æ–™è¡¨\n")
    
    # ç‚ºæ¯å€‹è¡¨ç”Ÿæˆæè¿°
    for idx, table in enumerate(tables, 1):
        # å–å¾—æ¬„ä½è³‡è¨Š
        cur.execute("""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = %s
            ORDER BY ordinal_position;
        """, (table,))
        columns = cur.fetchall()
        
        # å–å¾—ä¸»éµ
        cur.execute("""
            SELECT kcu.column_name
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage kcu
                ON tc.constraint_name = kcu.constraint_name
            WHERE tc.constraint_type = 'PRIMARY KEY'
                AND tc.table_schema = 'public'
                AND tc.table_name = %s;
        """, (table,))
        pk_columns = [r[0] for r in cur.fetchall()]
        
        # å–å¾—å¤–éµ
        cur.execute("""
            SELECT
                kcu.column_name as from_column,
                ccu.table_name as to_table,
                ccu.column_name as to_column
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage kcu
                ON tc.constraint_name = kcu.constraint_name
            JOIN information_schema.constraint_column_usage ccu
                ON ccu.constraint_name = tc.constraint_name
            WHERE tc.constraint_type = 'FOREIGN KEY'
                AND tc.table_schema = 'public'
                AND tc.table_name = %s;
        """, (table,))
        fks = cur.fetchall()
        
        # ç”Ÿæˆè¡¨æè¿°ï¼ˆç¬¦åˆ extract_table_descriptions æ ¼å¼ï¼‰
        prompt_parts.append(f"{idx}. **{table}** - {table.replace('_', ' ').title()} è³‡æ–™è¡¨")
        
        # æ¬„ä½æè¿°
        for col_name, data_type, is_nullable, col_default in columns:
            col_desc = f"   - {col_name} ({data_type}"
            
            # æ¨™è¨˜ä¸»éµ
            if col_name in pk_columns:
                col_desc += ", ä¸»éµ"
            
            # æ¨™è¨˜å¤–éµ
            for fk_col, ref_table, ref_col in fks:
                if fk_col == col_name:
                    col_desc += f", å¤–éµ: å°æ‡‰ {ref_table}.{ref_col}"
                    break
            
            col_desc += ")"
            
            # æ¨™è¨˜å¯ç‚ºç©º
            if is_nullable == 'YES':
                col_desc += " [å¯ç‚ºç©º]"
            
            prompt_parts.append(col_desc)
        
        prompt_parts.append("")  # ç©ºè¡Œ
    
    # åŠ å…¥å·¥ä½œæµç¨‹èªªæ˜
    prompt_parts.append("\n## å·¥ä½œæµç¨‹ (é‡è¦!)\n")
    prompt_parts.append("âš ï¸ **åŸ·è¡Œä»»ä½• SQL æŸ¥è©¢å‰ï¼Œä½ å¿…é ˆå…ˆå‘¼å« search_saved_correct_tool_uses æœå°‹ç›¸ä¼¼å•é¡Œ!**\n")
    prompt_parts.append("1. ç”¨æˆ¶æå•")
    prompt_parts.append("2. ğŸ” **å…ˆæœå°‹**: å‘¼å« search_saved_correct_tool_uses(question=\"ç”¨æˆ¶çš„å•é¡Œ\")")
    prompt_parts.append("3. åƒè€ƒæœå°‹çµæœä¸­çš„ SQL æ¨¡å¼")
    prompt_parts.append("4. åŸ·è¡Œ SQL: å‘¼å« run_sql(sql=\"SELECT ...\")")
    # prompt_parts.append("5. ğŸ’¾ **å„²å­˜æˆåŠŸçµæœ**: å‘¼å« save_question_tool_args(question=\"ç”¨æˆ¶çš„å•é¡Œ\", tool_name=\"run_sql\", args={\"sql\": \"SELECT ...\"})\n")
    # prompt_parts.append("   âš ï¸ æ³¨æ„: save_question_tool_args å¿…é ˆåŒ…å«ä¸‰å€‹åƒæ•¸: question, tool_name, args\n")
    
    # åŠ å…¥å›æ‡‰é¢¨æ ¼
    prompt_parts.append("## å›æ‡‰é¢¨æ ¼\n")
    prompt_parts.append("- ç°¡æ½”å°ˆæ¥­ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡")
    # prompt_parts.append("- åŸ·è¡ŒæŸ¥è©¢å¾Œï¼Œè§£é‡‹çµæœçš„å•†æ¥­æ„ç¾©")
    # prompt_parts.append("- ä¸»å‹•å»ºè­°è¦–è¦ºåŒ–åœ–è¡¨")
    
    return "\n".join(prompt_parts)


# === Auto Generate Fewshot API ===
def analyze_pg_database(conn):
    """åˆ†æ PostgreSQL è³‡æ–™åº«çµæ§‹"""
    cur = conn.cursor()

    cur.execute("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
        ORDER BY table_name;
    """)
    tables = [r[0] for r in cur.fetchall()]

    schema = {}
    for t in tables:
        cur.execute("""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = %s
            ORDER BY ordinal_position;
        """, (t,))
        cols = cur.fetchall()

        cur.execute("""
            SELECT
                kcu.column_name as from_column,
                ccu.table_name as to_table,
                ccu.column_name as to_column
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage kcu
                ON tc.constraint_name = kcu.constraint_name
            JOIN information_schema.constraint_column_usage ccu
                ON ccu.constraint_name = tc.constraint_name
            WHERE tc.constraint_type = 'FOREIGN KEY'
                AND tc.table_schema = 'public'
                AND tc.table_name = %s;
        """, (t,))
        fks = cur.fetchall()

        schema[t] = {"columns": cols, "fks": fks}

    return tables, schema


def build_fk_graph(tables, schema):
    """å»ºç«‹ FK é—œä¿‚åœ–"""
    graph = {t: [] for t in tables}
    for t in tables:
        for fk in schema[t]["fks"]:
            from_col, ref_table, to_col = fk
            if ref_table in graph:
                graph[t].append((ref_table, from_col, to_col))
                graph[ref_table].append((t, to_col, from_col))
    return graph


def bfs_join_tables(root, graph):
    """BFS å–å¾— JOIN é †åº"""
    visited = set()
    queue = [root]
    order = []
    while queue:
        t = queue.pop(0)
        if t in visited:
            continue
        visited.add(t)
        order.append(t)
        for to_table, _, _ in graph[t]:
            if to_table not in visited:
                queue.append(to_table)
    return order


def get_pg_sample_row(conn, table):
    """å–å¾—ç¯„ä¾‹è³‡æ–™"""
    cur = conn.cursor()
    try:
        cur.execute(f'SELECT * FROM "{table}" LIMIT 1;')
        row = cur.fetchone()
        if row is None:
            return None
        cols = [c[0] for c in cur.description]
        return dict(zip(cols, row))
    except Exception as e:
        logger.error(f"Error getting sample row from {table}: {e}")
        return None


def generate_fewshot_sql(root, join_order, schema, graph, sample_row):
    """ç”Ÿæˆ few-shot SQL"""
    aliases = {t: f"t{i}" for i, t in enumerate(join_order)}

    sql_parts = []
    sql_parts.append("SELECT " + ", ".join(f'{aliases[t]}.*' for t in join_order))
    sql_parts.append(f'FROM "{root}" {aliases[root]}')

    for t in join_order:
        if t == root:
            continue
        parent = None
        parent_fk = None
        for pt in join_order:
            if pt == t:
                break
            for to_table, from_col, to_col in graph[pt]:
                if to_table == t:
                    parent = pt
                    parent_fk = (from_col, to_col)
                    break
            if parent:
                break
        if parent:
            p_alias = aliases[parent]
            t_alias = aliases[t]
            from_col, to_col = parent_fk
            sql_parts.append(f'LEFT JOIN "{t}" {t_alias} ON {p_alias}."{from_col}" = {t_alias}."{to_col}"')

    # WHERE æ¢ä»¶
    exclude_cols = {"id", "created_at", "updated_at"}
    exclude_types = {"date", "timestamp with time zone", "timestamp without time zone"}
    
    where_cols = []
    for col in schema[root]["columns"]:
        name, ctype = col[0], (col[1] or "").lower()
        if name.lower() in exclude_cols or ctype in exclude_types:
            continue
        if sample_row and sample_row.get(name) is not None:
            where_cols.append((name, ctype))
    
    random.shuffle(where_cols)
    where_cols = where_cols[:2]
    
    if where_cols:
        conditions = []
        for name, ctype in where_cols:
            if "char" in ctype or "text" in ctype:
                conditions.append(f't0."{name}" LIKE \'%[{name}]%\'')
            else:
                conditions.append(f't0."{name}" = [{name}]')
        sql_parts.append("WHERE " + " AND ".join(conditions))

    sql_parts.append("LIMIT 100;")
    return "\n".join(sql_parts)


def extract_table_descriptions(system_prompt: str) -> dict:
    """å¾ system_prompt æå–è¡¨çš„æè¿°"""
    import re
    descriptions = {}
    
    # åŒ¹é… **table_name** - æè¿° çš„æ ¼å¼
    pattern = r'\*\*(\w+)\*\*\s*-\s*([^\n]+)'
    matches = re.findall(pattern, system_prompt)
    
    for table_name, desc in matches:
        descriptions[table_name.lower()] = desc.strip()
    
    return descriptions


def generate_question(root_table, join_order, table_descriptions=None):
    """ç”Ÿæˆè‡ªç„¶èªè¨€å•é¡Œ"""
    table_descriptions = table_descriptions or {}
    
    # å˜—è©¦å¾æè¿°ä¸­å–å¾—è¡¨çš„ä¸­æ–‡åç¨±
    root_desc = table_descriptions.get(root_table.lower(), root_table)
    
    if len(join_order) == 1:
        return f"æŸ¥è©¢{root_desc}çš„è³‡æ–™"
    else:
        related_descs = []
        for t in join_order[1:3]:
            desc = table_descriptions.get(t.lower(), t)
            related_descs.append(desc)
        
        related = ", ".join(related_descs)
        if len(join_order) > 3:
            related += " ç­‰"
        return f"æŸ¥è©¢{root_desc}åŠé—œè¯çš„{related}è³‡æ–™"


@app.post("/api/agents/{agent_id}/generate-fewshot", tags=["Training"], summary="è‡ªå‹•ç”Ÿæˆ Few-shot")
async def generate_fewshot(agent_id: str):
    """
    è‡ªå‹•ç”Ÿæˆ few-shot è¨“ç·´è³‡æ–™
    
    æœƒè‡ªå‹•:
    1. é€£æ¥ Agent çš„ PostgreSQL è³‡æ–™åº«
    2. åˆ†æè³‡æ–™åº«çµæ§‹(è¡¨,æ¬„ä½,å¤–éµé—œä¿‚)
    3. ç”Ÿæˆ JOIN SQL æŸ¥è©¢ç¯„ä¾‹
    4. å¾ system_prompt æå–è¡¨çš„ä¸­æ–‡æè¿°
    5. ç”Ÿæˆè‡ªç„¶èªè¨€å•é¡Œ
    6. å„²å­˜åˆ° ChromaDB ä½œç‚º few-shot ç¯„ä¾‹
    
    Args:
        agent_id: Agent ID
        
    Returns:
        - message: ç”Ÿæˆçµæœè¨Šæ¯
        - total_tables: è³‡æ–™åº«ç¸½è¡¨æ•¸
        - imported: æˆåŠŸåŒ¯å…¥çš„ few-shot æ•¸é‡
        - fewshots: ç”Ÿæˆçš„ few-shot åˆ—è¡¨
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    config = agent_configs[agent_id]
    
    # é€£æ¥è³‡æ–™åº«
    pg_user = config.get("postgres_user")
    pg_password = config.get("postgres_password")
    pg_host = config.get("postgres_host")
    pg_port = config.get("postgres_port") or "5432"
    pg_db = config.get("postgres_db")
    
    logger.info(f"Connecting to {pg_host}:{pg_port}/{pg_db}")
    
    conn = None
    try:
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            user=pg_user,
            password=pg_password,
            dbname=pg_db,
            connect_timeout=10
        )
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        raise HTTPException(500, f"è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
    
    try:
        tables, schema = analyze_pg_database(conn)
        logger.info(f"Found {len(tables)} tables")
        graph = build_fk_graph(tables, schema)
        
        # å¾ system_prompt æå–è¡¨æè¿°
        system_prompt = config.get("system_prompt", "")
        table_descriptions = extract_table_descriptions(system_prompt)
        logger.info(f"Extracted {len(table_descriptions)} table descriptions from prompt")
        
        fewshots = []
        for table in tables:
            try:
                sample = get_pg_sample_row(conn, table)
                if not sample:
                    logger.info(f"Skipping {table}: no data")
                    continue
                
                join_order = bfs_join_tables(table, graph)
                sql = generate_fewshot_sql(table, join_order, schema, graph, sample)
                question = generate_question(table, join_order, table_descriptions)
                
                fewshots.append({
                    "question": question,
                    "tool_name": "run_sql",
                    "sql": sql,
                    "table": table,
                })
                logger.info(f"Generated fewshot for {table}")
            except Exception as e:
                logger.error(f"Error generating fewshot for {table}: {e}")
                continue
        
        conn.close()
        conn = None
        
        logger.info(f"Generated {len(fewshots)} fewshots, importing to ChromaDB...")
        
        # åŒ¯å…¥åˆ° ChromaDB
        memory = get_agent_memory(agent_id, create_if_not_exists=True)
        context = RequestContext(user=User(id="admin"))
        
        imported = 0
        for fs in fewshots:
            try:
                await memory.save_tool_usage(
                    question=fs["question"],
                    tool_name=fs["tool_name"],
                    args={"sql": fs["sql"]},
                    context=context,
                    success=True,
                    metadata={"table": fs["table"], "auto_generated": True},
                )
                imported += 1
            except Exception as e:
                logger.error(f"Failed to save fewshot for {fs['table']}: {e}")
        
        return {
            "message": f"æˆåŠŸç”Ÿæˆ {imported} ç­† few-shot",
            "total_tables": len(tables),
            "imported": imported,
            "fewshots": fewshots,
        }
        
    except Exception as e:
        if conn:
            conn.close()
        logger.error(f"Generate fewshot failed: {e}")
        raise HTTPException(500, f"ç”Ÿæˆå¤±æ•—: {e}")


@app.post("/api/agents/{agent_id}/generate-system-prompt", tags=["Training"], summary="è‡ªå‹•ç”Ÿæˆ System Prompt")
async def generate_system_prompt_api(agent_id: str):
    """
    å¾è³‡æ–™åº«è‡ªå‹•ç”Ÿæˆ system prompt
    
    æœƒè‡ªå‹•åˆ†æè³‡æ–™åº«çµæ§‹ï¼Œç”ŸæˆåŒ…å«ï¼š
    - æ‰€æœ‰è¡¨çš„æè¿°ï¼ˆç¬¦åˆ extract_table_descriptions æ ¼å¼ï¼‰
    - æ¬„ä½è³‡è¨Šï¼ˆé¡å‹ã€ä¸»éµã€å¤–éµï¼‰
    - å·¥ä½œæµç¨‹èªªæ˜
    - å›æ‡‰é¢¨æ ¼æŒ‡å¼•
    
    Args:
        agent_id: Agent ID
        
    Returns:
        - system_prompt: ç”Ÿæˆçš„ system prompt
        - total_tables: è³‡æ–™åº«ç¸½è¡¨æ•¸
    """
    if agent_id not in agent_configs:
        raise HTTPException(404, f"Agent '{agent_id}' not found")
    
    config = agent_configs[agent_id]
    
    # é€£æ¥è³‡æ–™åº«
    pg_user = config.get("postgres_user")
    pg_password = config.get("postgres_password")
    pg_host = config.get("postgres_host")
    pg_port = config.get("postgres_port") or "5432"
    pg_db = config.get("postgres_db")
    
    logger.info(f"Connecting to {pg_host}:{pg_port}/{pg_db}")
    
    conn = None
    try:
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            user=pg_user,
            password=pg_password,
            dbname=pg_db,
            connect_timeout=10
        )
        
        # ç”Ÿæˆ system prompt
        system_prompt = generate_system_prompt_from_db(conn, pg_db)
        
        # è¨ˆç®—è¡¨æ•¸é‡
        cur = conn.cursor()
        cur.execute("""
            SELECT COUNT(*) 
            FROM information_schema.tables 
            WHERE table_schema = 'public' AND table_type = 'BASE TABLE';
        """)
        total_tables = cur.fetchone()[0]
        
        conn.close()
        
        return {
            "system_prompt": system_prompt,
            "total_tables": total_tables,
            "message": f"æˆåŠŸç”Ÿæˆ system promptï¼ŒåŒ…å« {total_tables} å¼µè¡¨"
        }
        
    except Exception as e:
        if conn:
            conn.close()
        logger.error(f"Generate system prompt failed: {e}")
        raise HTTPException(500, f"ç”Ÿæˆå¤±æ•—: {e}")


@app.on_event("startup")
async def startup():
    """å•Ÿå‹•æ™‚è¼‰å…¥å·²å„²å­˜çš„ agents"""
    saved_configs = load_agents_config()
    for agent_id, config in saved_configs.items():
        try:
            port = config.pop("port", None)  # å–å‡ºä¹‹å‰çš„ port
            agent_configs[agent_id] = config
            start_agent(agent_id, config, port)
        except Exception as e:
            logger.error(f"Failed to load agent '{agent_id}': {e}")

    logger.info(f"Loaded {len(agent_configs)} agents")


@app.on_event("shutdown")
async def shutdown():
    """é—œé–‰æ™‚åœæ­¢æ‰€æœ‰ agents"""
    for agent_id in list(agent_processes.keys()):
        stop_agent(agent_id)


if __name__ == "__main__":
    import uvicorn

    print("=" * 50)
    print("Vanna Multi-Agent Server")
    print("=" * 50)
    print("ç®¡ç† API: http://localhost:8100")
    print("Agent ports: 8101, 8102, 8103...")
    print("=" * 50)
    uvicorn.run(app, host="0.0.0.0", port=8100)
